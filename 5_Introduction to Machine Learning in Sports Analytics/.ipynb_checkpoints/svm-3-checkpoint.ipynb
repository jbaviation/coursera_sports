{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-75099f02-f2c9-46a6-9900-e9e9e224769c",
    "deepnote_cell_type": "markdown",
    "etc_hash": "01166d09973c3ea586e4bf396eadbee0e40319e602b712867dff1ec9542f20e9",
    "tags": []
   },
   "source": [
    "# Cross Validation\n",
    "Anytime we are building predictive models we need to consider a number of things, and chiefly\n",
    "among these is how we train the model when using the `fit()` function. This function does all the heavy\n",
    "lifting for us, and will use all of the data we give it to try and learn the best model it can. This\n",
    "can lead to overfitting, where the model created works really well on the data it was given, but\n",
    "doesn't generalize well to new data. Now, we've already seen two tactics: first, we separate our data\n",
    "into a train/test set, this gives us a realistic understanding of how well our model will perform on\n",
    "new data, and second, we can change model parameters like `C` to penalize overfitting.\n",
    "\n",
    "But really how big should your\n",
    "train/test split be? A more common approach in modern machine learning is to not have a strict split\n",
    "of your data, but instead to have many different splits of your data and train many models, to get a\n",
    "better estimate of how well the model might work. This is called cross validation, and sklearn has\n",
    "support build right into the `model_selection` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "00001-3dc6c8fc-a402-485f-8169-5f053e986cfa",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "etc_hash": "033a61bb7665aae41687843e21331f481273b74148beaac3551aa4fd905ab6d0",
    "execution_millis": 480,
    "execution_start": 1621860651401,
    "source_hash": "2c22a084",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pitch_type</th>\n",
       "      <th>release_speed</th>\n",
       "      <th>release_pos_x</th>\n",
       "      <th>release_pos_z</th>\n",
       "      <th>player_name</th>\n",
       "      <th>batter</th>\n",
       "      <th>events</th>\n",
       "      <th>description</th>\n",
       "      <th>zone</th>\n",
       "      <th>des</th>\n",
       "      <th>...</th>\n",
       "      <th>home_score</th>\n",
       "      <th>away_score</th>\n",
       "      <th>bat_score</th>\n",
       "      <th>fld_score</th>\n",
       "      <th>post_away_score</th>\n",
       "      <th>post_home_score</th>\n",
       "      <th>post_bat_score</th>\n",
       "      <th>post_fld_score</th>\n",
       "      <th>if_fielding_alignment</th>\n",
       "      <th>of_fielding_alignment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FS</td>\n",
       "      <td>81.2</td>\n",
       "      <td>-1.0920</td>\n",
       "      <td>6.3157</td>\n",
       "      <td>Jake Faria</td>\n",
       "      <td>435622</td>\n",
       "      <td>run</td>\n",
       "      <td>ball</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Wild pitch by pitcher Jake Faria.   Sam Hillia...</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Strategic</td>\n",
       "      <td>Strategic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FF</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-0.8826</td>\n",
       "      <td>6.4818</td>\n",
       "      <td>Jake Faria</td>\n",
       "      <td>435622</td>\n",
       "      <td>NaN</td>\n",
       "      <td>called_strike</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Strategic</td>\n",
       "      <td>Strategic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SL</td>\n",
       "      <td>83.8</td>\n",
       "      <td>-0.9456</td>\n",
       "      <td>6.2833</td>\n",
       "      <td>Jake Faria</td>\n",
       "      <td>602074</td>\n",
       "      <td>single</td>\n",
       "      <td>hit_into_play_no_out</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Yonathan Daza singles on a bunt ground ball to...</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Standard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FF</td>\n",
       "      <td>92.3</td>\n",
       "      <td>-0.8358</td>\n",
       "      <td>6.3745</td>\n",
       "      <td>Jake Faria</td>\n",
       "      <td>602074</td>\n",
       "      <td>NaN</td>\n",
       "      <td>foul</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Standard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FF</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-0.7746</td>\n",
       "      <td>6.4466</td>\n",
       "      <td>Jake Faria</td>\n",
       "      <td>656541</td>\n",
       "      <td>walk</td>\n",
       "      <td>ball</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Sam Hilliard walks.</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Infield shift</td>\n",
       "      <td>Standard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  pitch_type  release_speed  release_pos_x  release_pos_z player_name  batter  \\\n",
       "0         FS           81.2        -1.0920         6.3157  Jake Faria  435622   \n",
       "1         FF           90.0        -0.8826         6.4818  Jake Faria  435622   \n",
       "2         SL           83.8        -0.9456         6.2833  Jake Faria  602074   \n",
       "3         FF           92.3        -0.8358         6.3745  Jake Faria  602074   \n",
       "4         FF           93.0        -0.7746         6.4466  Jake Faria  656541   \n",
       "\n",
       "   events           description  zone  \\\n",
       "0     run                  ball  13.0   \n",
       "1     NaN         called_strike   5.0   \n",
       "2  single  hit_into_play_no_out   2.0   \n",
       "3     NaN                  foul   5.0   \n",
       "4    walk                  ball  11.0   \n",
       "\n",
       "                                                 des  ... home_score  \\\n",
       "0  Wild pitch by pitcher Jake Faria.   Sam Hillia...  ...          3   \n",
       "1                                                NaN  ...          3   \n",
       "2  Yonathan Daza singles on a bunt ground ball to...  ...          3   \n",
       "3                                                NaN  ...          3   \n",
       "4                              Sam Hilliard walks.    ...          3   \n",
       "\n",
       "  away_score bat_score fld_score post_away_score  post_home_score  \\\n",
       "0          3         3         3               3                3   \n",
       "1          3         3         3               3                3   \n",
       "2          3         3         3               3                3   \n",
       "3          3         3         3               3                3   \n",
       "4          3         3         3               3                3   \n",
       "\n",
       "  post_bat_score  post_fld_score  if_fielding_alignment  of_fielding_alignment  \n",
       "0              3               3              Strategic              Strategic  \n",
       "1              3               3              Strategic              Strategic  \n",
       "2              3               3               Standard               Standard  \n",
       "3              3               3               Standard               Standard  \n",
       "4              3               3          Infield shift               Standard  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's bring in our imports and baseball data as we did before\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "\n",
    "filename=\"assets/baseball_svm_data.zip\"\n",
    "df=pd.read_csv(zipfile.ZipFile(filename).open(\"reg_Sep2019.csv\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "00002-4bba62c1-cb8a-44ec-8433-4ef2716e6ea7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "etc_hash": "747d63dbe5a78ccd97e3456b8b0e03f7c63260412eb400dddae6e0adcfcb4bb7",
    "execution_millis": 28,
    "execution_start": 1621860651875,
    "source_hash": "a80ed729",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pitch_type\n",
       "CH            Changeup 4485\n",
       "CU           Curveball 4141\n",
       "EP                 Eephus 3\n",
       "FC              Cutter 2309\n",
       "FF    4-Seam Fastball 14039\n",
       "FS         Split Finger 575\n",
       "FT     2-Seam Fastball 3203\n",
       "KC        Knuckle Curve 656\n",
       "SI              Sinker 2924\n",
       "SL              Slider 7656\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sincer we're old hats at this now, I'm going to add in a bit more data. Let's move from a binary\n",
    "# prediction into a multiclass prediction. Specifically, it seems we can differentiated from two\n",
    "# kinds of pitches, let's add in a few more. Here's a list of all of the different pitches and the\n",
    "# number of them in our datafile.\n",
    "df.groupby(\"pitch_type\").apply(lambda z: f\"{z['pitch_name'].unique()[0]} {len(z)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "00003-f31f5edd-f2db-4f57-b6c4-5d92fd396ca0",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "etc_hash": "af95675299c2122b6f08d41f25f9dfccaf50655446f52ea6657afce8ef80eb97",
    "execution_millis": 1,
    "execution_start": 1621860653164,
    "source_hash": "4c4868aa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We can see there is a fair bit of diversity here, but we have significant class imbalance. Turns\n",
    "# out very few pitches just lob the ball out there with an Eephus pitch -- I know I've never seen\n",
    "# one! But let's try and predict all of these different types, and lets use a host of different\n",
    "# features. First up: pitching metrics\n",
    "pitch_metrics=['release_spin_rate','release_extension','release_pos_y','release_pos_x','release_pos_z','effective_speed']\n",
    "\n",
    "# I think we should add the pitcher name too, why not? It could be that some pitchers have favorites\n",
    "player_metrics=['player_name']\n",
    "\n",
    "# Pitchers might change their strategy when they already have outs, or when they are deep in the\n",
    "# game.\n",
    "game_details=['outs_when_up','inning']\n",
    "\n",
    "# Take a minute and think about what you know about the game of baseball. What other features might\n",
    "# be predictive of the next pitch a pitcher will throw?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "00004-2118888f-f398-4cec-a678-fb9bb375fbe8",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "etc_hash": "5780d9cd8555787aaaf749d3d39f88222c4fd51b1d2baad4180476e674065284",
    "execution_millis": 15,
    "execution_start": 1621860654326,
    "source_hash": "f3cec215",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now let's combine our features and reduce our DataFrame\n",
    "df=df[[*pitch_metrics, *player_metrics, *game_details, \"pitch_type\"]]\n",
    "\n",
    "# Now let's drop where any of the pitches are nan\n",
    "df=df.dropna(subset=[\"pitch_type\"])\n",
    "\n",
    "# I also want to factorize on the player name, since we need numeric values for SVMs\n",
    "df['player_name']=df['player_name'].factorize()[0]\n",
    "\n",
    "# That should give us roughly 40,000 observances. Let's prune out roughly 35,000 for our validation set\n",
    "df_validation=df[-35000:]\n",
    "df_pitches=df[0:-35000]\n",
    "\n",
    "features=[*pitch_metrics, *player_metrics, *game_details]\n",
    "\n",
    "# Now let's impute data for the missing data in our training set. There are not many, so I'm just going\n",
    "# to use a simple mean approach\n",
    "df_pitches=df_pitches.fillna(df_pitches.mean(numeric_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "00005-98ace841-7417-4d0f-ab76-f7cf97eee6b5",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "etc_hash": "9464723ab03edee12dee4379a8f8eb75bcadc4f0d30d5d4c07f804c030e68dcc",
    "execution_millis": 44414,
    "execution_start": 1621860655345,
    "source_hash": "b1332908",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# In a cross validation approach we break the original data into a number of equal subsets, called folds, \n",
    "# and then we hold one of those for testing and we train on the rest. We repeat this procedure for each fold. \n",
    "# Sometimes this is called k-fold cross validation, where k is the number of folds you use. And of course,\n",
    "# sklearn has this built in for us\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import svm\n",
    "\n",
    "# Now we create the model we are interested in. Now, the linear SVM did well and it was nice and simple,\n",
    "# but it turns out that the default implementation of the linear SVM in sklearn is pretty slow, and our\n",
    "# data is getting up there in size. The fifth degree polynomial seemed to have the same accuracy and is\n",
    "# and is roughly ten times faster on this data.\n",
    "clf=svm.SVC(kernel='poly', degree=5, C=15, coef0=5, random_state=1337)\n",
    "\n",
    "# Once we have this done, we simply give the model and the data to sklearn, tell it how many folds we want\n",
    "# to perform - in this case I'll do just 5 folds - and then what metrics we want to use to evaluate how\n",
    "# good the fit was. We're going to keep using accuracy here, but as you'll see in the future, that's not\n",
    "# really ideal given that we have such high class imbalance\n",
    "results=cross_validate(clf,df_pitches[features],df_pitches[\"pitch_type\"],cv=5,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00007-52e0c963-aaef-4cd9-b0e5-03fcc0a882a1",
    "deepnote_cell_type": "markdown",
    "etc_hash": "0665114edc6ccd57762d9d71dd70c915ed663d64c0b418f43175a599c423f739",
    "tags": []
   },
   "source": [
    "Ok, while that's crunching away - and remember, this is almost 5,000 observations we are going to fit five times over, so it's going to take awhile - lets talk about what you actually use cross validation for. Cross validation does not improve your model. Your model is going to be trained on all of the training data you have when it comes to actually building your final model. Cross validation does not change the hyperparameters you are using either. Instead, cross validation gives you a stronger understanding of how generalizable your model will be to new data. Think of it this way, you might have created a great model on September's baseball data, which is the data we are using, but if it doesn't generalize to October they're going to laugh back in the office pool. You don't want that.\n",
    "\n",
    "The cross validation in the notebook should be done by now, let's go check it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "00007-1aa69d19-7b25-4c82-84e1-bffc552d8987",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "etc_hash": "8c2eef9a08674d48164031bbb3eb8f78a1a9b15670ef13a93c0618a2027fa81a",
    "execution_millis": 9,
    "execution_start": 1621860699763,
    "source_hash": "565d7f8b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cv score results are [0.61961962 0.66933868 0.66132265 0.63226453 0.63326653]\n",
      "The average cv score results are 0.6431624008778318 with a standard deviation of 0.018899451244109383\n"
     ]
    }
   ],
   "source": [
    "# The results of the corss_validate() function are a dictionary which has some timing information and\n",
    "# our test scores, and it's this last one that we're most interested in\n",
    "print(f\"The cv score results are {results['test_score']}\")\n",
    "\n",
    "# And since we have now run many different models, we can get an overall average as well as a standard\n",
    "# deviation, which is helpful in knowing how likely we are to get a model with a given accuracy.\n",
    "print(f\"The average cv score results are {np.mean(results['test_score'])} with a standard deviation of {np.std(results['test_score'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "00007-e6176538-db3a-4af9-8a66-7847331b3d0f",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "etc_hash": "43843e6cccedb031a551726b791b654ec2729a68e81191be98ca3e46cce0b249",
    "execution_millis": 14048,
    "execution_start": 1621860699770,
    "source_hash": "95d98cf8",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5673428571428571"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Great, so how well does this model *actually* work on our validation data? Well, let's take a look!\n",
    "# First, we need to independly impute the missing values\n",
    "df_validation=df_validation.fillna(df_validation.mean(numeric_only=True))\n",
    "\n",
    "# Now we can check this against our trained (fitted) classifier\n",
    "clf.fit(df_pitches[features],df_pitches[\"pitch_type\"])\n",
    "clf.score(df_validation[features],df_validation[\"pitch_type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00009-a3a387a9-d6e5-46cd-aec2-06d4bf821713",
    "deepnote_cell_type": "markdown",
    "etc_hash": "e483385c5ed4ac21607ea280798aed33caf2c82debe73ff799ea13ede227f55d",
    "tags": []
   },
   "source": [
    "Ok, that's an overview of how we can apply support vector machines to pitch data from the MLB. Now, our accuracy at the end didn't seem like it was very good - only 57%. But we are predicting across many different classes of pitches, and it's not really clear where our model goes wrong. Does it mispredict one class completely? Or is it equally bad at all of the classes? The answer is, I don't know, but I know how to find out, and in the next lecture we're going to look at a different dataset where this comes up, and I'll show you the techniques data scientists use to understand their model performance better."
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "4985d0e5-5907-4a6d-9979-3aa9b2f12a25",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
