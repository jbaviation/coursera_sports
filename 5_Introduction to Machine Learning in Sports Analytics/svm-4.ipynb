{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-1f1619c9-3a28-4f76-a9d8-2144efc6c37e",
    "deepnote_cell_type": "markdown",
    "etc_hash": "0b5025e226c6c1c1d0ded38661c715da5e3c042ec5cd0528a32f9bcfba3584d2",
    "tags": []
   },
   "source": [
    "# A Real World SVM Model: Boxing Punch Classification\n",
    "To this point we've really looked at some of our own work using SVMs for prediction in professional major league sports, but I want to pick up the research end and I want to do that with wearables in particular. A lot of our features have been nice and cleaned and easy to understand, but wearables are producing huge noisy data streams which are really difficult to interpret at times. For instance, this little IMU device can capture acceleration in three dimensions, gyroscope data, temperature, light, pressure, and more, and it costs about $100 and lasts for a day. Even more, it can capture some of these measurements at a rate of almost 1,000 times per second. That's an incredible amount of data.\n",
    "\n",
    "So what happens when we strap a few of these to an athelete, and what can we do with that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00002-3120ee97-999b-47cd-9dec-b53beead57c9",
    "deepnote_cell_type": "markdown",
    "etc_hash": "8c062ab5b6760533443ce547cfc43fe0f347a0f8daa9e61bc38e4bc611fbbb3e",
    "tags": []
   },
   "source": [
    "A great place to start this investigation is with some replication wortk. Matthew Worsey et al. (2020) described an approach to \n",
    "automatic classification of boxing punches through motion sensors and machine learning. In this work, they trained a model on a single athelete who wore sensors at each wrist as well as one in the middle of the upper back - at the T3 vertebrae. Each sensor captured three dimensions of spatial position as well as rotation and acceleration. To collect training data, they classified  250 punches the athelete threw: a left jab, hook, and uppercut, and a right cross and right uppercut. Following good practices they captured equal sized numbers of each punch type (50 each).\n",
    "\n",
    "After training a model, they then evaluated it on a hold-out dataset of 82 punches across the five categories, all done by the same athelete.\n",
    "They built several predictive models to see if they could predict from the sensor data the kind of punch thrown, and one of the models was an\n",
    "SVM model. They've done the hard work of collecting the data for us, so why don't we dig in and see if we can build our own models.\n",
    "\n",
    "-----\n",
    "Worsey, Matthew T.O.; Espinosa, Hugo G.; Shepherd, Jonathan B.; Thiel, David V. 2020. \"An Evaluation of Wearable Inertial Sensor Configuration and Supervised Machine Learning Models for Automatic Punch Classification in Boxing\" IoT 1, no. 2: 360-381. https://doi.org/10.3390/iot1020021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00002-bf5e8132-70bb-4c88-b00e-429b86c698a1",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "etc_hash": "76bf75f1114b89fc53b14c3720ac59b86304c1b975af6e4f187d0cca2edeb19a",
    "execution_millis": 61275,
    "execution_start": 1621864441272,
    "source_hash": "b6c7f2b1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The data the authors provided have over 100 different features setup for us. Each feature represents a set of summary \n",
    "# statistics from the the underlying sensor data, but Matthew was kind enough to send me the processed data so we could\n",
    "# use it. But he did send me the raw data as well, and I just want to take a moment to explain what it looks like.\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "\n",
    "filename=\"assets/gust_boxing.zip\"\n",
    "df_raw=pd.read_excel(zipfile.ZipFile(filename).open(\"GUST_boxing_classification_data/Raw_sensor_training_data.xlsx\"),sheet_name=\"Left wrist\")\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00003-67d82790-b349-421e-b54a-5520dc124dd4",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "etc_hash": "71d9e2130af9f8ab5111db7814fa2a32422e7fdb6ece5225fdca01f517a9c2be",
    "execution_millis": 303,
    "execution_start": 1621864502590,
    "source_hash": "8d8d5f59",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If we look we can see the sampling rate was at 250 times a second, and we have the acceleration and rotation in\n",
    "# the X, Y, and Z space. They determine when a punch connected based on the impact of the glove sensor. Then, they\n",
    "# partitioned the data 0.6 seconds before and after this point. At 250 Hz that means there were 300 sensor observations\n",
    "# for each sensor for each punch.\n",
    "\n",
    "# Let's just take a look at the first 300 observations for the X axis acceleration on the left wrist here:\n",
    "df_raw[\"Accel_x (g)\"].iloc[0:299].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00004-bc5ade6c-d82f-44b5-b553-4e1644ad4357",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "etc_hash": "ad88069aad8517cf038f183fc5eb51cf18d35f891290b38e748ba2a93684c9af",
    "execution_millis": 28,
    "execution_start": 1621864502879,
    "source_hash": "ddc6136c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# So, how would we actually feed this into an SVM? Well, the approach they took was to generate some summary\n",
    "# statistics which describe the distribution you see. For instance:\n",
    "features={}\n",
    "features[\"Ax_mean\"]=df_raw[\"Accel_x (g)\"].iloc[0:299].mean()\n",
    "features[\"Ax_std\"]=df_raw[\"Accel_x (g)\"].iloc[0:299].std()\n",
    "features[\"Ax_min\"]=df_raw[\"Accel_x (g)\"].iloc[0:299].min()\n",
    "features[\"Ax_kurtosis\"]=df_raw[\"Accel_x (g)\"].iloc[0:299].kurtosis()\n",
    "features[\"Ax_skew\"]=df_raw[\"Accel_x (g)\"].iloc[0:299].skew()\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00005-b572c635-1530-45db-97d3-47a4161e562b",
    "deepnote_cell_type": "markdown",
    "etc_hash": "56e286ebba5e51bbf12398389da1d6aafb998d151cd2eb18521c39b225902f0d",
    "tags": []
   },
   "source": [
    "Ok, so that's the approach Worsey and team took to take this very rapid fine-grained sensor data and turn it into momentary features for classifying boxing punches. But, there lots of different ways one could do this. So here's a bit of thought experiment, imagine you were doing this study and you could put sensors anywhere on the boxer's body. Now, where would you put them, and how might you generate features from the underlying sensor data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00004-85136b51-ebde-46da-8e2c-568d6dfe86dd",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "etc_hash": "0adf8e8b0813a0ef9d3cccfd1f0d248eacad563ea75db97fd137944fd6de52aa",
    "execution_millis": 1908,
    "execution_start": 1621864502899,
    "source_hash": "4a5a2a2b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# With a bit of a discussion of the data done, let's give it a go with building some SVMs. Let's bring in our \n",
    "# typical data processing and svm libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Now we will read in the boxing data. We'll start with just one sensor, the sensor\n",
    "# placed on the T3 vertebrae (upper back). The authors have separated the training\n",
    "# and testing datasets for us so this is straightforward\n",
    "import zipfile\n",
    "filename=\"assets/gust_boxing.zip\"\n",
    "df_train=pd.read_csv(zipfile.ZipFile(filename).open(\"GUST_boxing_classification_data/Training_features_T3_sensor.csv\"))\n",
    "df_test=pd.read_csv(zipfile.ZipFile(filename).open(\"GUST_boxing_classification_data/Evaluation_features_T3_sensor.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00003-e997ad68-74e9-491b-8027-43bf5dbb7bd7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "etc_hash": "e0ddc565cd9ab6c3460e42dbfb386f90c6882f46668973b5b1237bac7919042d",
    "execution_millis": 30091,
    "execution_start": 1621864504808,
    "source_hash": "59a35e6b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In the datafiles the class column is our y predictors\n",
    "X_train=df_train[df_train.columns.drop(\"class\")]\n",
    "y_train=df_train[\"class\"]\n",
    "X_test=df_test[df_test.columns.drop(\"class\")]\n",
    "y_test=df_test[\"class\"]\n",
    "\n",
    "# Now we can set our model and use cross validation to see how accurate it is\n",
    "clf=svm.SVC(kernel='linear')\n",
    "results=cross_validate(clf,X_train,y_train,cv=5,scoring='accuracy')\n",
    "\n",
    "# And we'll print the results of our model accuracy\n",
    "print(f\"The cv score results are {results['test_score']}\")\n",
    "print(f\"The average cv score results are {np.mean(results['test_score'])} with a standard deviation of {np.std(results['test_score'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00003-ac265b59-5ef0-4eac-a132-14c46aa74ba2",
    "deepnote_cell_type": "markdown",
    "etc_hash": "3439afe2125f931494986a98f02d948ae2a34e6471ea61c1e21d37c5ba20781e",
    "tags": []
   },
   "source": [
    "Alright! That looks like a pretty good classifier, sitting around 90% accurate! Let's take a look at how well it works on the holdout test set we were provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00004-04cebc5b-8d44-4735-98cf-9b61d0f43634",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "etc_hash": "4b2849b08aee7ea04d7833b7030d5d23a1050b383f77ebe69ebbbe90c4a279df",
    "execution_millis": 8038,
    "execution_start": 1621864534905,
    "source_hash": "7b063cf6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First we need to fit the model, remember that here we are not going to use\n",
    "# cross validation for fitting the model, we are going to fit the model with all\n",
    "# of our data because we have a dedicated hold out set and this should give us\n",
    "# the strongest accuracy\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "# Now lets compare the accuracy between our predicted outcomes and our known\n",
    "# outcomes\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(clf.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00005-814c80af-e301-4d82-b5d9-f2a32024cdd4",
    "deepnote_cell_type": "markdown",
    "etc_hash": "75887bff6e7989fb58dc503eda85fc65305b749d00f2704267e6b8e3d6792aa6",
    "tags": []
   },
   "source": [
    "So that's a bit deflating - the accuracy is significantlly lower than the accuracy we had previously seen. But don't get too worried yet, we need to talk about what accuracy\n",
    "really means. In this context, accuracy is whether the exact label is predicted as\n",
    "intended. As you increase the number of classes - in this case to five - you would expect\n",
    "that there would be a hard time just getting the predicted value correct by chance. For\n",
    "instance, if just guessed randomly at the outcome of two teams playing against one another, you would expect to be right roughly half the time - 50%. But now that we have\n",
    "5 classes to guess from, your chance of being correct - assumiung each class happened with equal frequency - is 20%. So accuracy is a bit of a misleading metric, and is one which is rarely used for descision making with machine learning models.\n",
    "\n",
    "Instead, let's look at a new method to understand our model: the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00001-7580103e-b91e-4ebc-a366-d27bc05a1c78",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "etc_hash": "0e3d703337a1ae346aadd3d9338e97045857286ad8d24ff5e9fc2756c2cb0c3a",
    "execution_millis": 519,
    "execution_start": 1621869201697,
    "source_hash": "b6ffdb44",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scikit-Learn has a handy option to plot a confusion matrix. In this plot, which\n",
    "# is a heatmap, the True labels (correct values) are plotted against the Predicted\n",
    "# labels (those generated by our classifier).\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "# We have a lot of different parameters we can submit to this function. The first\n",
    "# three are core, and include the classifier we want to use, followed by the data\n",
    "# we want to run through the classifier. In this case, that's our holdout test\n",
    "# set, first the features X_test and followed by the class labels y_test. Then\n",
    "# I'm going to tell sklearn what the class labels means, how to display them, and\n",
    "# what coloring I want to be shown.\n",
    "matrix=plot_confusion_matrix(clf, X_test, y_test, xticks_rotation='vertical', cmap='cividis')\n",
    "\n",
    "# And I'm just going to tweak the size of the figure so it's easier to see\n",
    "matrix.figure_.set_size_inches(8,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00007-c65a9238-bc85-4d31-9c26-6af03f011e64",
    "deepnote_cell_type": "markdown",
    "etc_hash": "5c1a7402ec4a9d875e95833ddd599f2b3b5e3927e2853d15f00d8466b30cbbbc",
    "tags": []
   },
   "source": [
    "Take a moment to study the confusion matrix. The y axis on the left are the labels that come from\n",
    "our data, called the true labels. Along the bottom axis are the labels which our classifier predicted.\n",
    "The color of each cell corresponds to the number of instances which intersect with the labeled data\n",
    "and our classifier prediction. Each cell is color coded, dark blue means there were no instances at\n",
    "the intersection, and bright yellow means there were a lot. A perfect classifier with an accuracy of\n",
    "100% would show a bright yellow diagonal line on the confusion matrix, showing perfect alignment\n",
    "between observed and predicted classes.\n",
    "\n",
    "We can use that knowledge to quickly make sense of the confusion matrix - several of the bright yellow\n",
    "squares fall along the diagonal, and we can see that our classifier is good at predicting right \n",
    "uppercuts as well as left jobs and hooks. If we look at the bottom right hand corner we see that the\n",
    "right uppercut is not well predicted by this model. Reading the bottom row, we can see that there were\n",
    "13 instances of a right uppercut (just sum all the numbers), but that only 7 of them were correctly\n",
    "classified, and that our classifier predicted a number of them to be left jabs, uppercuts, or even a right\n",
    "cross.\n",
    "\n",
    "And let's talk about that left jab for a moment - if you find the row labeled with a left jab you'll\n",
    "notice that our model made no correct predictions for this class! Instead, the model predicted the\n",
    "vast majority of them as right crosses, and a few of them as left hooks. This is a great example of\n",
    "why the confusion matrix is neccessary to understand how your model is making errors -- this model is\n",
    "pretty good with correctly predicting many different punches, but is unable to make an even chance\n",
    "prediction for the left jab, and severely overpredicts whether a punch will be a right cross."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00008-cb35fc8e-3cc2-4cff-a54b-a937435e676c",
    "deepnote_cell_type": "markdown",
    "etc_hash": "2d96f6d491d341b331e61edaa4ed8fc1bbbe109de648f312c122d068043084b5",
    "tags": []
   },
   "source": [
    "I think this data does a great job of demonstrating why you can't just take accuracy as a metric and think it tells the whole story. Instead, the confusion matrix gives you a much better understanding of where things are going wrong. This can be helpful both in estimating the performance of the model in the real world -- in this case that left jab just isn't going to show up -- and in iterating on your features.\n",
    "\n",
    "Of course, in this data I've intentionally just looked at one sensor, the one on the back at T3. It seems natural to me that including data with respect to the gloves themselves would clean up this classification problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00014-49bb7fb2-987a-41d9-84ee-05ebbd4224a1",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "etc_hash": "83aa38f8277d31cf0881d3ea9189d0da4370e73782946194ce8f1fa03cadd897",
    "execution_millis": 7,
    "execution_start": 1621869953814,
    "source_hash": "85b9e37f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# But let's end off this lecture with a little more discussion of metrics. I think inspection of that\n",
    "# confusion matrix is important for you as the sports data scientist, but sometimes you want a way\n",
    "# to more simply describe the data. The first metric we can look at the precision of the classifier. \n",
    "# In a multiclass predictor such as this, this is the ratio of the true positives divided by the\n",
    "# combined number of true and false positives for that class. For instance, in this model we never\n",
    "# make a prediction of a right upper cut and are wrong. So 7/(7+0)=1. However, we regularly predict\n",
    "# the right cross and are wrong, so there the precision is low (15/15+(3+15+2))\n",
    "from sklearn.metrics import precision_score\n",
    "df_precision=pd.DataFrame([precision_score(y_test,clf.predict(X_test),average=None)],columns=sorted(y_test.unique()))\n",
    "df_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00015-cfe8de79-0801-4e56-bb27-2330ea36a2b2",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "etc_hash": "130d3f940ed94dc8c8fc29f725efe09a4836f00d3b8e82106d4188a9b4aa5e4b",
    "execution_millis": 44,
    "execution_start": 1621870061136,
    "source_hash": "9e257574",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Recall, on the other hand, is the number of true positives divided by the true positives and\n",
    "# false *negatives*. This score gets smaller when you incorrectly predict that a given was a given \n",
    "# class (a false negative). In this case, the right cross recall is much better (93%), since \n",
    "# we very rarely will see a right cross punch and predict it to be something else (only one\n",
    "# example here where we predicted a left uppercut and it ended up being a right cross)\n",
    "from sklearn.metrics import recall_score\n",
    "df_recall=pd.DataFrame([recall_score(y_test,clf.predict(X_test),average=None)],columns=sorted(y_test.unique()))\n",
    "df_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00010-f19cdb8f-d965-42e8-8814-fc7b4cd31e09",
    "deepnote_cell_type": "markdown",
    "etc_hash": "2172508ad2baed950154e7db5d486f8a72c4e866878d685ef099247db3252a88",
    "tags": []
   },
   "source": [
    "All right, so this wraps up our introduction to Support Vector Machines. We saw how, when you are using a binary class prediction like fastball or changeup and only two features such as speed and spin we can visualize the descision boundary - the street - as a straight line with a linear SVM. The modeling technique gets its name from the datapoints which constrain this line, and they are called the support vectors. We don't have to have to cast this as a linear problem though, and can build a polynomial kernel and constrain it in different ways to learn a better fitting descision boundary.\n",
    "\n",
    "More generally we call these boundaries hyperplanes, and we can apply them in n-dimensions and use many different features. We also don't have to constrain our model to binary classification, as you saw in this lecture where we tackled a five class prediction. Finally, we dove in a bit more on how to evaluate how good a model actually is, including understanding the confusion matrix as a sensemaking device, and the precision and recall statistics as different ways to summarize aspects of the confusion matrix."
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "2d2ab479-9b01-4407-9f18-7f4544955c1a",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
