{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d0d39d3-f600-4aa2-a5dd-4012ed746d57",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning in Sports Analytics\n",
    "This notebook contains the notes taken from the 5th and final course in the Coursera Sports Analytics Program."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cbd232-150a-4e47-bb57-0600c806146a",
   "metadata": {},
   "source": [
    "## Week 1\n",
    "### What is Machine Learning?\n",
    "- Think of machine learning as a paradigm of building computation models based on historical data without explicitly creating rules\n",
    "- The models are built iteratively (at least conceptually):\n",
    "    - Some data is collected about a phenomena\n",
    "    - Statistical methods are applied to the data to organize it\n",
    "    - The resulting model can be used for new data\n",
    "\n",
    "#### Breaking Down Machine Learning\n",
    "There are a few main branches of Machine Learning depending upon the task:\n",
    "\n",
    "##### Supervised Learning\n",
    "- The task is to learn the relationship between <ins>historical data</ins> and some <ins>labels</ins> which already exist\n",
    "- The labels are usually provided by humans, and the goal of the models created is to predict the labels on new data which does not have a label\n",
    "- There are two broad categories of supervised approaches\n",
    "    - **Regression**, where the label is a <ins>target value</ins> such as the draft pick position of a player which you might predict from their previous performance\n",
    "    - **Classification**, where the label is a <ins>class value</ins> and is categorical in nature, such as predicting the kind of activity based on sensor data from wearables\n",
    "- This class will focus entirely on this form of machine learning\n",
    "\n",
    "##### Unsupervised Learning\n",
    "- These approaches do not require the label.  The historical data is used to identify common features about the data which could be used to understand new data\n",
    "- Most common task is <ins>clustering</ins> of data, which is sometimes just done statistically or is done with visualization of data in mind\n",
    "- In sports analytics there are numerous great examples:\n",
    "    - Which players are similar based on their stats?\n",
    "    - Which physical activities share similar sensor data?\n",
    "    - Which teams have similar playing patterns?\n",
    "- Despite not having a label, human decision making is still an important part of the process in determining which features you are clustering on\n",
    "    - A model clustering NHL players where goal scoring and location on ice will differentiate players by position, while one trained on time on ice and salary will differentiate between team investment choices\n",
    "\n",
    "##### Semi-Supervised Learning\n",
    "- Involves a mixture of supervised and unsupervised learning approaches where the human labeling of data is expensive or incomplete\n",
    "- For instance, imagine you've scraped the web and have a collection of thousands of pictures of athletes and you want to analyse what pair of shoes they are each wearing using computer vision and machine learning\n",
    "    - Individual shoe identification may be difficult and error prone\n",
    "    - **Seeding** the system with a few classifications (supervised approach) can be used to identify features of the images which can be used to cluster unlabeled images (unsupervised approach) which then can be used for more labeling\n",
    "\n",
    "##### Reinforcement Learning\n",
    "- A method of training a supervised method where a human does not provide labels but the machine can sense the labels in its environment\n",
    "- Most commonly this is done by providing some fucntion which rewards the machine for correctly classifying data in real-time without human intervention\n",
    "- An example of this might be in sport analytics is with amateur athlete training, where some broad objective is known and can be measure (eg compliance with a training program which could be read from wearable data) and the machine is able to take some interventions and try and make this happen (eg email or phone app nudges)\n",
    "- Ther relationship between when and how often to send emails is then learned from watching the effectiveness they have on compliance with the training program\n",
    "- This is similar to A/B or Randomised Control Trial (RCT) but done with machine learning instead of equal proportions of subjects\n",
    "\n",
    "#### The Machine Learning Space\n",
    "- Supervised (classification, regression)\n",
    "- Unsupervised (clustering)\n",
    "- Semisupervised\n",
    "- Reinforcement\n",
    "\n",
    "### The Machine Learning Workflow\n",
    "- **Process Data**\n",
    "    - Determine features likely to be of significance to the task\n",
    "    - Acquire and clean data to create these features\n",
    "    - Label data\n",
    "\n",
    "- **Create Models**\n",
    "    - Identify model choice and evaluation strategy\n",
    "    - Separate data into training, validation, and testing data sets\n",
    "    - Train and tune models using training/validation data\n",
    "    - Evaluate model performance on testing data\n",
    "\n",
    "- **Deploy Model**\n",
    "    - Make predictions on unseen data and evaluate in the wild\n",
    "    - Expand through iterations as needed\n",
    "    \n",
    "#### Processing Data: Defining Your ML Problem\n",
    "- Starts with thinking about the problem, what is it you want to model and predict?\n",
    "    - Game score, match outcome, player salary, movement result, etc.\n",
    "- The details matter in the prediction:\n",
    "    - Do you just care about the accuracy of the model? Or do you want the model to be interpretable?\n",
    "    - How generalizable do you expect the model to be? Where will you use this model?\n",
    "    - These start to inform your data collection, modeling, and evaluation strategies\n",
    "- What are the ideal features (or attributes) you think would be useful?\n",
    "    - Break this list down into those you have high confidence in and those that you are less sure of (lean towards breadth when doing this)\n",
    "- Be as explicit as possible and be aware of potential scope creep\n",
    "\n",
    "#### Processing Data: Acquiring Data\n",
    "A common challenge! There are three broad categories:<br>\n",
    "\n",
    "- You purchase the data from a third party\n",
    "    - There are numerous data vendors specifically set up to provide sports outcomes data largely with an eye towards gambling and risk management markets\n",
    "    - Pricing depends on a few aspects of the data: historical size, accuracy, specific features, frequency\n",
    "- Web Scraping\n",
    "    - Complex and wonderful space\n",
    "    - Lot of technical, ethical, and legal considerations around the access of web data\n",
    "    - Web scraping can be a very fragile way to obtain data: are you building a proof of concept, or a longer-lived service?\n",
    "- First party data collection\n",
    "    - Especially common with wearable technologies and data scientists embedded in sports teams\n",
    "    - Can be integral in some tasks, and highly valuable in competitive tasks\n",
    "    \n",
    "#### Processing Data: Labeling Data\n",
    "- Core to your question: what are you tring to predict?\n",
    "- Several different approaches:\n",
    "    - Often there is a ground truth which can be objectively observed, such as the score of a match or the outcome of a tournament\n",
    "    - Sometimes the label must be added by a human expert as it isn't found in the data you have (eg the MVP or stars of the game might be announced on TV but not found in web-scraped data)\n",
    "    - Sometimes you want to engage a group of experts to help label your data\n",
    "        - Commonly called crowdwork, with the general idea being that you can speed up the labeling of data, collect diverse, or achieve a consensus in difficult tasks\n",
    "        - Lots of important considerations on accuracy when labeling data\n",
    "    - When classifying data, is your data balanced among classes? If not, are you able to collect more for minority classes?\n",
    "    \n",
    "#### Create Models: Choosing a Model\n",
    "- Choosing the right modeling technique could be a course in itself\n",
    "    - Some techniques reult in a model which is more interpretable than others (eg Decision Trees)\n",
    "    - Some require large amounts of data to work well (eg Neural Networks)\n",
    "    - Some require significant computational resources (eg Deep Learning)\n",
    "    - And of course, some will just work better for the particular problem and data that you have\n",
    "- Start simple instead of going for the *latest and greatest*\n",
    "    - In this course we'll demonstrate some specific fundamental models which have good results and can work well with moderate sized datasets: Decision Trees, Support Vector Machines (SVMs), and Regression Trees\n",
    "    - But we'll go a bit further, and talk about how you can bring multiple different models together to improve accuracy through a process called ensembles\n",
    "\n",
    "#### Create Models: Partitioning Your Data\n",
    "- When training a model you want to ensure it is generalizable to new data so that the predictive power is high\n",
    "- To do this, we partition the data into three sets:\n",
    "    - **Training data**: the data the learning algorithm sees to learn from and create a model\n",
    "    - **Validation data**: the data you use to evaluate the quality of the model as you are training it\n",
    "    - **Test data**: the data your client uses to understand how well your model performs\n",
    "- Coneptually you and your client might be the same person!\n",
    "    - The more your learning algorithm can observe evidence from your validation or test sets the more likely it is to overtrain to that data\n",
    "- When partitioning your data it is common to use an 80/20 rule, however, this is not alway appropriate, we'll go thru examples later\n",
    "\n",
    "#### Create Models: Evaluating Your Model\n",
    "- This is aplace where your goal really matters\n",
    "    - Do you want to predict who isn't going to win a tournament with high accuracy? That's easy\n",
    "- There are different metrics and each ehlps inform us about how a model practices within the context of a question\n",
    "    - Let's say we are predicting who is going to be in the NCAA March Madness tournament\n",
    "    - There are 68 teams who make it out of 350\n",
    "    - We can naively get an accuracy rate of 80% just by predicting no one will make it!\n",
    "- Accuracy is almost always an inappropriate measure, and there are many better measures depending on your goal\n",
    "    - **Kappa**: chance corrected accuracy\n",
    "    - **Precision**: true positives divided by true positives and false positives\n",
    "    - **Recall**: true positives diveded by true positives and false negatives\n",
    "    - **F1 Score**: a combination of precision and recall\n",
    "    \n",
    "#### Deploy Model\n",
    "- Once you have built and evaluated your model you are ready to deploy it in production\n",
    "- This is where engineering comes in\n",
    "    - Pipelines of data and modeling, resulting in continually improving systems\n",
    "    - Timeliness of the model and predictions, especially if you are predicting in live settings\n",
    "    - Feasibility of predictions, do you need to apply models on an embedded device?\n",
    "- One challenge is including hard-to-measure information in the process\n",
    "    - When does a significant event (eg covid) invalidate expectations of generalizability?\n",
    "    - When do new data sources provide an opportunity to improve the model?\n",
    "    - How can judgement from humans be integrated in a probabilistic way?\n",
    "- Deployment is very specific to goals of solving the problem\n",
    "\n",
    "### Our First Model: NHL Game Outcomes\n",
    "Follow the [hockey_wins](./hockey_wins-1.ipynb) notebook for an overview of this process\n",
    "\n",
    "#### Reflection on NHL Game Outcomes\n",
    "- We did a lot! Throughout the process we:\n",
    "    - Acquired data, through APIs and light weight web-scraping\n",
    "    - Cleaned the data, aligning values throughout\n",
    "    - Made choices on features, putting our knowledge of the sport into our analysis\n",
    "    - Made decisions on how to represent missing data\n",
    "    - Ran a fair analysis, building a model on 800 observations and evaluating its accuracy on the remaining ~500 items\n",
    "- But, let's throw up a few flags\n",
    "    - Lots of our choices were pretty arbitrary and naive\n",
    "    - Our features from the previous season were not inspected deeply\n",
    "    - We don't have a sense as to where this model will likely be good and where it will be bad\n",
    "    \n",
    "### Considerations in Deploying The Model\n",
    "#### Considerations in Using the Game Predictor Model\n",
    "- There are a lot of considerations to apply this kind of model in practice\n",
    "    - Does your model generalize well?\n",
    "    - Which features are important to the accuracy of the model?\n",
    "    - Is there bias in the model?\n",
    "- There are both techniques to apply to detect these issues as well as techniques to mitigate problems that might arise from them\n",
    "- Let's explore our hockey game data a little bit more, with the goal of *sensemaking*, or to learn how it actually works\n",
    "\n",
    "#### Example of Deploying our NHL Game Outcomes Model\n",
    "Follow the [hockey_wins2](./hockey_wins-2.ipynb) notebook for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d6a6b0-599a-4662-9856-b01244ffaa63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
